<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Performing inference on new data &mdash; myria3d 3.3.2 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sphinx_paramlinks.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="How to train new models" href="../guides/train_new_model.html" />
    <link rel="prev" title="Preparing data for training" href="prepare_dataset.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> myria3d
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="install_on_linux.html">Install Myria3D on Linux</a><ul>
<li class="toctree-l2"><a class="reference internal" href="install_on_linux.html#setting-up-a-virtual-environment">Setting up a virtual environment</a></li>
<li class="toctree-l2"><a class="reference internal" href="install_on_linux.html#install-source-as-a-package">Install source as a package</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="install_on_wsl2.html">Install Myria3D on WSL2 with CUDA support</a><ul>
<li class="toctree-l2"><a class="reference internal" href="install_on_wsl2.html#setting-up-wsl2">Setting up WSL2</a></li>
<li class="toctree-l2"><a class="reference internal" href="install_on_wsl2.html#installing-anaconda">Installing Anaconda</a></li>
<li class="toctree-l2"><a class="reference internal" href="install_on_wsl2.html#installing-myria3d">Installing Myria3D</a></li>
<li class="toctree-l2"><a class="reference internal" href="install_on_wsl2.html#install-cuda-in-wsl">Install cuda in WSL</a></li>
<li class="toctree-l2"><a class="reference internal" href="install_on_wsl2.html#troubleshooting">Troubleshooting</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="prepare_dataset.html">Preparing data for training</a><ul>
<li class="toctree-l2"><a class="reference internal" href="prepare_dataset.html#peprocessing-functions">Peprocessing functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="prepare_dataset.html#preparing-the-dataset">Preparing the dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="prepare_dataset.html#getting-started-quickly-with-a-toy-dataset">Getting started quickly with a toy dataset</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Performing inference on new data</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#run-inference-from-source">Run inference from source</a></li>
<li class="toctree-l2"><a class="reference internal" href="#run-inference-from-sources">Run inference from sources</a></li>
<li class="toctree-l2"><a class="reference internal" href="#run-inference-from-within-a-docker-image">Run inference from within a docker image</a></li>
<li class="toctree-l2"><a class="reference internal" href="#additional-options-for-prediction">Additional options for prediction</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../guides/train_new_model.html">How to train new models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../guides/train_new_model.html#setup">Setup</a></li>
<li class="toctree-l2"><a class="reference internal" href="../guides/train_new_model.html#quick-run">Quick run</a></li>
<li class="toctree-l2"><a class="reference internal" href="../guides/train_new_model.html#training">Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="../guides/train_new_model.html#testing-the-model">Testing the model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../guides/train_new_model.html#inference">Inference</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../guides/development.html">Developer’s guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../guides/development.html#code-versionning">Code versionning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../guides/development.html#tests">Tests</a></li>
<li class="toctree-l2"><a class="reference internal" href="../guides/development.html#continuous-integration-ci">Continuous Integration (CI)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../guides/development.html#continuous-delivery-cd">Continuous Delivery (CD)</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Background</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../background/interpolation.html">KNN-Interpolation to merge multiple predictions [TODO]</a></li>
<li class="toctree-l1"><a class="reference internal" href="../background/general_design.html">General design of the package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../background/general_design.html#model-should-be-fast-performant-and-practical">Model should be fast, performant, and practical</a></li>
<li class="toctree-l2"><a class="reference internal" href="../background/general_design.html#subsampling-is-important-to-improve-point-cloud-structure">Subsampling is important to improve point cloud structure</a></li>
<li class="toctree-l2"><a class="reference internal" href="../background/general_design.html#speed-is-of-the-essence">Speed is of the essence</a></li>
<li class="toctree-l2"><a class="reference internal" href="../background/general_design.html#evaluation-is-key-to-select-the-right-approach">Evaluation is key to select the right approach</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../apidoc/scripts.html">Scripts</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../apidoc/scripts.html#run">run</a></li>
<li class="toctree-l2"><a class="reference internal" href="../apidoc/scripts.html#myria3d-train">myria3d.train</a></li>
<li class="toctree-l2"><a class="reference internal" href="../apidoc/scripts.html#module-myria3d.predict">myria3d.predict</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../apidoc/configs.html">Default configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../apidoc/myria3d.pctl.html">myria3d.pctl</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../apidoc/myria3d.pctl.html#module-myria3d.pctl.datamodule">myria3d.pctl.datamodule</a></li>
<li class="toctree-l2"><a class="reference internal" href="../apidoc/myria3d.pctl.html#module-myria3d.pctl.dataset">myria3d.pctl.dataset</a></li>
<li class="toctree-l2"><a class="reference internal" href="../apidoc/myria3d.pctl.html#module-myria3d.pctl.dataloader">myria3d.pctl.dataloader</a></li>
<li class="toctree-l2"><a class="reference internal" href="../apidoc/myria3d.pctl.html#module-myria3d.pctl.points_pre_transform">myria3d.pctl.points_pre_transform</a></li>
<li class="toctree-l2"><a class="reference internal" href="../apidoc/myria3d.pctl.html#module-myria3d.pctl.transforms">myria3d.pctl.transforms</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../apidoc/myria3d.model.html">myria3d.models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../apidoc/myria3d.model.html#model">Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../apidoc/myria3d.model.html#module-myria3d.models.interpolation">Interpolation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../apidoc/myria3d.models.modules.html">myria3d.models.modules</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../apidoc/myria3d.models.modules.html#pytorch-geometric-randla-net">(Pytorch-Geometric) RandLA-Net</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../apidoc/myria3d.callbacks.html">myria3d.callbacks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../apidoc/myria3d.callbacks.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../apidoc/myria3d.callbacks.html#module-myria3d.callbacks.comet_callbacks">myria3d.callbacks.comet_callbacks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../apidoc/myria3d.callbacks.html#module-myria3d.callbacks.finetuning_callbacks">myria3d.callbacks.finetuning_callbacks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../apidoc/myria3d.callbacks.html#module-myria3d.callbacks.logging_callbacks">myria3d.callbacks.logging_callbacks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../apidoc/myria3d.callbacks.html#module-myria3d.callbacks">Module contents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../apidoc/myria3d.utils.html">myria3d.utils</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../apidoc/myria3d.utils.html#module-myria3d.utils.utils">myria3d.utils.utils</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">myria3d</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Performing inference on new data</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/tutorials/make_predictions.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="performing-inference-on-new-data">
<h1>Performing inference on new data<a class="headerlink" href="#performing-inference-on-new-data" title="Permalink to this headline"></a></h1>
<p>Refer to the tutorials (<a class="reference internal" href="install_on_linux.html"><span class="doc std std-doc">Linux</span></a>, <a class="reference internal" href="install_on_wsl2.html"><span class="doc std std-doc">Windows</span></a>) for installation instructions.</p>
<p>To run inference, you will need:</p>
<ul class="simple">
<li><p>A source cloud point in LAS format on which to infer classes and probabilites. Sample data from the French “Lidar HD” project can be downloaded at <a class="reference external" href="https://geoservices.ign.fr/lidarhd">this address</a>.</p></li>
<li><p>A checkpoint of a trained lightning module implementing model logic (class <code class="docutils literal notranslate"><span class="pre">myria3d.models.model.Model</span></code>)</p></li>
<li><p>A minimal yaml configuration specifying parameters. We use <a class="reference external" href="https://hydra.cc/">hydra</a> to manage configurations, and this yaml results from the model training. The <code class="docutils literal notranslate"><span class="pre">datamodule</span></code> and <code class="docutils literal notranslate"><span class="pre">model</span></code> parameters groups must match dataset characteristics and model training settings.  The <code class="docutils literal notranslate"><span class="pre">predict</span></code> parameters group specifies path to models and data as well as batch size (N=50 works well, the larger the faster) and use of gpu (optionnal). For hints on what to modify, see the <code class="docutils literal notranslate"><span class="pre">experiment/predict.yaml</span></code> file.</p></li>
</ul>
<blockquote>
<div><p><strong>A default model and its configuration are embedded directly in code under folder <code class="docutils literal notranslate"><span class="pre">trained_model_assets</span></code>.</strong> They are expected to always be compatible with the code base, and updated as needed in case of e.g. change of configuration format or model implementation.</p>
</div></blockquote>
<section id="run-inference-from-source">
<h2>Run inference from source<a class="headerlink" href="#run-inference-from-source" title="Permalink to this headline"></a></h2>
<p>Then, fill out the {missing parameters} below and run:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python run.py <span class="se">\</span>
task.task_name<span class="o">=</span>predict <span class="se">\</span>
predict.src_las<span class="o">={</span>/path/to/cloud.las<span class="o">}</span> <span class="se">\</span>
predict.output_dir<span class="o">={</span>/path/to/out/dir/<span class="o">}</span> <span class="se">\</span>
predict.gpus<span class="o">={</span><span class="m">0</span> <span class="k">for</span> none, <span class="o">[</span>i<span class="o">]</span> to use GPU number i<span class="o">}</span> <span class="se">\</span>
datamodule.batch_size<span class="o">={</span>N<span class="o">}</span>
</pre></div>
</div>
<p>To show you current inference config, simply add a <code class="docutils literal notranslate"><span class="pre">--help</span></code> flag:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python run.py task.task_name<span class="o">=</span>predict --help
</pre></div>
</div>
<p>Note that <code class="docutils literal notranslate"><span class="pre">predict.src_las</span></code> may be any valid glob pattern (e.g. <code class="docutils literal notranslate"><span class="pre">/path/to/multiple_files/*.las</span></code>), in order to <strong>predict on multiple files successively</strong>.</p>
</section>
<section id="run-inference-from-sources">
<h2>Run inference from sources<a class="headerlink" href="#run-inference-from-sources" title="Permalink to this headline"></a></h2>
<p>In case you want to swicth to package-based inference, you will need to comment out the parameters that depends on local environment variables such as logger credentials and training data directory. You can do so by making a copy of your configuration file and commenting out the lines containing <code class="docutils literal notranslate"><span class="pre">oc.env</span></code> logic.</p>
</section>
<section id="run-inference-from-within-a-docker-image">
<h2>Run inference from within a docker image<a class="headerlink" href="#run-inference-from-within-a-docker-image" title="Permalink to this headline"></a></h2>
<p>Up to date docker images (named <code class="docutils literal notranslate"><span class="pre">myria3d</span></code>) are created via Github integration actions (see <a class="reference internal" href="../guides/development.html"><span class="doc std std-doc">Developer’s guide</span></a>.</p>
<p>A docker image encapsulating the virtual environment and application sources can also be built using the provided Dockerfile. At built time, the Dockerfile is not standalone and should be part of the repository - whose content is copied into the image - at the github reference you want to build from.</p>
<p>To run inference:</p>
<ul class="simple">
<li><p>Mount the needed volumes with the <code class="docutils literal notranslate"><span class="pre">-v</span></code> option.</p></li>
<li><p>Always set <code class="docutils literal notranslate"><span class="pre">--ipc=host</span></code> to allow multithreading (used in pytorch dataloader, as mentionned in <a class="reference external" href="https://github.com/pytorch/pytorch#using-pre-built-images">Pytorch’s README</a>).</p></li>
<li><p>Increase the shared memory with <code class="docutils literal notranslate"><span class="pre">--shm-size=2gb</span></code> (which should be enough for 1km*1km point French “Lidar HD” clouds).</p></li>
<li><p>Set <code class="docutils literal notranslate"><span class="pre">--gpus=all</span></code> to make gpus visible to the container if available.</p></li>
</ul>
<p>See <a class="reference external" href="https://github.com/anibali/docker-pytorch#running-pytorch-scripts">docker-pytorch README</a> for more details plus an additional option to specify user id at runtime.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># specify your paths here as needed</span>
docker run <span class="se">\</span>
-v <span class="o">{</span>local_inputs<span class="o">}</span>:/inputs/ <span class="se">\</span>
-v <span class="o">{</span>local_output<span class="o">}</span>:/outputs/ <span class="se">\</span>
--ipc<span class="o">=</span>host <span class="se">\</span>
--gpus<span class="o">=</span>all <span class="se">\</span>
--shm-size<span class="o">=</span>2gb <span class="se">\</span>
python run.py <span class="o">{</span>...config paths <span class="p">&amp;</span> options...<span class="o">}</span>
</pre></div>
</div>
</section>
<section id="additional-options-for-prediction">
<h2>Additional options for prediction<a class="headerlink" href="#additional-options-for-prediction" title="Permalink to this headline"></a></h2>
<section id="output-dimensions">
<h3>Output dimensions<a class="headerlink" href="#output-dimensions" title="Permalink to this headline"></a></h3>
<p>By default, the predicted classification is stored in a new <code class="docutils literal notranslate"><span class="pre">PredictedClassification</span></code> LAS dimension. The <a class="reference external" href="https://en.wikipedia.org/wiki/Entropy_(information_theory)">entropy</a> of probabilities is also stored in a new <code class="docutils literal notranslate"><span class="pre">entropy</span></code> LAS dimension. It can be used as a very limited proxy of uncertainty.</p>
<p>Change params <code class="docutils literal notranslate"><span class="pre">predict.interpolator.predicted_classification_channel</span></code> and <code class="docutils literal notranslate"><span class="pre">predict.interpolator.entropy_channel</span></code> to change name of output dimensions. Set to <code class="docutils literal notranslate"><span class="pre">null</span></code> to disable saving these dimensions.</p>
<p>One can control for which classes to save the probabilities. This is achieved with a <code class="docutils literal notranslate"><span class="pre">predict.interpolator.probas_to_save</span></code> config parameter, which can be either the <code class="docutils literal notranslate"><span class="pre">all</span></code> keyword (to save probabilities for all classes) or a list of specific classes (e.g. <code class="docutils literal notranslate"><span class="pre">predict.interpolator.probas_to_save=[building,vegetation]</span></code> - note the absence of space between class names).</p>
</section>
<section id="receptive-field-overlap-at-inference-time">
<h3>Receptive field overlap at inference time<a class="headerlink" href="#receptive-field-overlap-at-inference-time" title="Permalink to this headline"></a></h3>
<p>To improve spatial regularity of the predicted probabilities, one can make inference on square receptive fields that have a non-null overlap with each other. This has the effect of smoothing out irregular predictions. The resulting classification is better looking, with more homogeneous predictions at the object level.</p>
<p>To define an overlap between successive 50m*50m receptive fields, set <code class="docutils literal notranslate"><span class="pre">predict.subtile_overlap={value}</span></code>.
This, however, comes with a large computation price. For instance, <code class="docutils literal notranslate"><span class="pre">predict.subtile_overlap=25</span></code> means a 25m overlap on both x and y axes, which multiplies inference time by a factor of 4.</p>
</section>
<section id="ignoring-artefacts-points-during-inference">
<h3>Ignoring artefacts points during inference<a class="headerlink" href="#ignoring-artefacts-points-during-inference" title="Permalink to this headline"></a></h3>
<p>Lidar acquisition may have produced artefacts points. If these points were identified with one (or several) classification code(s), they can be ignored during inference. These points will still be present in the output cloud, but will not negatively disturb model inference. They will keep their original class in the predicted classification dim. They will have null probas and entropy.</p>
<p>In the configuration, data transforms are used to drop points with a class 65. By convention, 65 will flag Lidar artefacts points. Additional classes may be mapped to 65 to be ignored during inference as well, via the <code class="docutils literal notranslate"><span class="pre">dataset_description.classification_preprocessing_dict</span></code> parameter. Note: you may need to use quotes when overriding this parameter via CLI.</p>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="prepare_dataset.html" class="btn btn-neutral float-left" title="Preparing data for training" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../guides/train_new_model.html" class="btn btn-neutral float-right" title="How to train new models" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Institut National de l&#39;Information Géographique et Forestière.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>